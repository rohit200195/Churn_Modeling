{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churn_Modeling_Bank_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_bQXSNvpspS",
        "colab_type": "text"
      },
      "source": [
        "#ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWK_FOAOp0wV",
        "colab_type": "text"
      },
      "source": [
        "Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jv0biR0pLxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jkvk3eeqADK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "70e20cc9-cb19-4372-be40-4a5b063a493b"
      },
      "source": [
        "#Importing dataset\n",
        "dataset = pd.read_csv(\"/content/Churn_Modelling.csv\")\n",
        "dataset.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBkWnXOqqNMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "747bafd9-af5a-40dc-85b7-5b42f9737778"
      },
      "source": [
        "X = dataset.iloc[:,3:13]\n",
        "X"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0             619    France  Female  ...          1               1        101348.88\n",
              "1             608     Spain  Female  ...          0               1        112542.58\n",
              "2             502    France  Female  ...          1               0        113931.57\n",
              "3             699    France  Female  ...          0               0         93826.63\n",
              "4             850     Spain  Female  ...          1               1         79084.10\n",
              "...           ...       ...     ...  ...        ...             ...              ...\n",
              "9995          771    France    Male  ...          1               0         96270.64\n",
              "9996          516    France    Male  ...          1               1        101699.77\n",
              "9997          709    France  Female  ...          0               1         42085.58\n",
              "9998          772   Germany    Male  ...          1               0         92888.52\n",
              "9999          792    France  Female  ...          1               0         38190.78\n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh8tQiuKqO5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0d36a82b-f68a-4c7a-c08f-a386159f3750"
      },
      "source": [
        "y = dataset.iloc[:,13]\n",
        "y"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-bFzrtpqjQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dummy Variables for categorical data\n",
        "geo = pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "gender = pd.get_dummies(X[\"Gender\"],drop_first=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2aQdj1CrtJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.concat([X,geo,gender],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZsgw8Hjrvso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.drop(['Geography','Gender'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGDU1cKsTtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size= 0.3,random_state=43)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDnvMTshss4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature Scalling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KENXoT2dtueB",
        "colab_type": "text"
      },
      "source": [
        "Make Artificial Nural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbCC6hWntia2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwu7cciuWc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAip3FeRuaki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74b97cca-eb49-4fb9-ccf9-a3958282f4f0"
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu',input_dim = 11))\n",
        "\n",
        "#Second Layer\n",
        "classifier.add(Dense(units = 6,kernel_initializer='he_uniform',activation='relu'))\n",
        "classifier.add(Dropout(0.20))\n",
        "#Third Layer\n",
        "classifier.add(Dense(units = 6,kernel_initializer='he_uniform',activation='relu'))\n",
        "classifier.add(Dropout(0.10))\n",
        "#Output Layer\n",
        "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "#Compile the ANN\n",
        "classifier.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_history = classifier.fit(X_train,Y_train,validation_split=0.3,batch_size=20,epochs=130)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4900 samples, validate on 2100 samples\n",
            "Epoch 1/130\n",
            "4900/4900 [==============================] - 1s 232us/step - loss: 0.5898 - acc: 0.7680 - val_loss: 0.5192 - val_acc: 0.8019\n",
            "Epoch 2/130\n",
            "4900/4900 [==============================] - 0s 84us/step - loss: 0.5240 - acc: 0.7941 - val_loss: 0.4917 - val_acc: 0.8019\n",
            "Epoch 3/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.5027 - acc: 0.7937 - val_loss: 0.4789 - val_acc: 0.8019\n",
            "Epoch 4/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4871 - acc: 0.7939 - val_loss: 0.4682 - val_acc: 0.8019\n",
            "Epoch 5/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.4772 - acc: 0.7941 - val_loss: 0.4607 - val_acc: 0.8019\n",
            "Epoch 6/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4705 - acc: 0.7951 - val_loss: 0.4543 - val_acc: 0.8019\n",
            "Epoch 7/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4639 - acc: 0.7951 - val_loss: 0.4499 - val_acc: 0.8038\n",
            "Epoch 8/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4580 - acc: 0.7959 - val_loss: 0.4460 - val_acc: 0.8033\n",
            "Epoch 9/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4574 - acc: 0.7992 - val_loss: 0.4431 - val_acc: 0.8048\n",
            "Epoch 10/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.4567 - acc: 0.7971 - val_loss: 0.4409 - val_acc: 0.8048\n",
            "Epoch 11/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4534 - acc: 0.7978 - val_loss: 0.4395 - val_acc: 0.8062\n",
            "Epoch 12/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4498 - acc: 0.7986 - val_loss: 0.4377 - val_acc: 0.8057\n",
            "Epoch 13/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4463 - acc: 0.8045 - val_loss: 0.4361 - val_acc: 0.8062\n",
            "Epoch 14/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4451 - acc: 0.8004 - val_loss: 0.4349 - val_acc: 0.8071\n",
            "Epoch 15/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4393 - acc: 0.8055 - val_loss: 0.4333 - val_acc: 0.8071\n",
            "Epoch 16/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4384 - acc: 0.8067 - val_loss: 0.4319 - val_acc: 0.8071\n",
            "Epoch 17/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4361 - acc: 0.8098 - val_loss: 0.4303 - val_acc: 0.8110\n",
            "Epoch 18/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.4380 - acc: 0.8118 - val_loss: 0.4286 - val_acc: 0.8138\n",
            "Epoch 19/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4314 - acc: 0.8114 - val_loss: 0.4266 - val_acc: 0.8167\n",
            "Epoch 20/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4255 - acc: 0.8116 - val_loss: 0.4241 - val_acc: 0.8176\n",
            "Epoch 21/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4260 - acc: 0.8149 - val_loss: 0.4216 - val_acc: 0.8190\n",
            "Epoch 22/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4277 - acc: 0.8198 - val_loss: 0.4192 - val_acc: 0.8214\n",
            "Epoch 23/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4204 - acc: 0.8218 - val_loss: 0.4168 - val_acc: 0.8219\n",
            "Epoch 24/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4184 - acc: 0.8237 - val_loss: 0.4148 - val_acc: 0.8233\n",
            "Epoch 25/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4146 - acc: 0.8261 - val_loss: 0.4118 - val_acc: 0.8243\n",
            "Epoch 26/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.4189 - acc: 0.8171 - val_loss: 0.4104 - val_acc: 0.8257\n",
            "Epoch 27/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.4110 - acc: 0.8257 - val_loss: 0.4077 - val_acc: 0.8290\n",
            "Epoch 28/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.4068 - acc: 0.8292 - val_loss: 0.4056 - val_acc: 0.8300\n",
            "Epoch 29/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.4050 - acc: 0.8271 - val_loss: 0.4038 - val_acc: 0.8310\n",
            "Epoch 30/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.4054 - acc: 0.8284 - val_loss: 0.4018 - val_acc: 0.8357\n",
            "Epoch 31/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.4003 - acc: 0.8333 - val_loss: 0.3993 - val_acc: 0.8376\n",
            "Epoch 32/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3982 - acc: 0.8327 - val_loss: 0.3977 - val_acc: 0.8390\n",
            "Epoch 33/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3951 - acc: 0.8333 - val_loss: 0.3963 - val_acc: 0.8419\n",
            "Epoch 34/130\n",
            "4900/4900 [==============================] - 0s 94us/step - loss: 0.3994 - acc: 0.8310 - val_loss: 0.3949 - val_acc: 0.8438\n",
            "Epoch 35/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3980 - acc: 0.8322 - val_loss: 0.3932 - val_acc: 0.8462\n",
            "Epoch 36/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3919 - acc: 0.8333 - val_loss: 0.3915 - val_acc: 0.8457\n",
            "Epoch 37/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3926 - acc: 0.8316 - val_loss: 0.3901 - val_acc: 0.8486\n",
            "Epoch 38/130\n",
            "4900/4900 [==============================] - 0s 93us/step - loss: 0.3898 - acc: 0.8359 - val_loss: 0.3883 - val_acc: 0.8495\n",
            "Epoch 39/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3887 - acc: 0.8355 - val_loss: 0.3870 - val_acc: 0.8505\n",
            "Epoch 40/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3864 - acc: 0.8376 - val_loss: 0.3861 - val_acc: 0.8514\n",
            "Epoch 41/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3857 - acc: 0.8365 - val_loss: 0.3842 - val_acc: 0.8548\n",
            "Epoch 42/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3809 - acc: 0.8367 - val_loss: 0.3832 - val_acc: 0.8533\n",
            "Epoch 43/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3805 - acc: 0.8384 - val_loss: 0.3821 - val_acc: 0.8538\n",
            "Epoch 44/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3769 - acc: 0.8408 - val_loss: 0.3813 - val_acc: 0.8538\n",
            "Epoch 45/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3752 - acc: 0.8431 - val_loss: 0.3801 - val_acc: 0.8538\n",
            "Epoch 46/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3782 - acc: 0.8376 - val_loss: 0.3790 - val_acc: 0.8538\n",
            "Epoch 47/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3774 - acc: 0.8365 - val_loss: 0.3774 - val_acc: 0.8514\n",
            "Epoch 48/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3737 - acc: 0.8408 - val_loss: 0.3764 - val_acc: 0.8538\n",
            "Epoch 49/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3735 - acc: 0.8384 - val_loss: 0.3756 - val_acc: 0.8519\n",
            "Epoch 50/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3722 - acc: 0.8431 - val_loss: 0.3747 - val_acc: 0.8524\n",
            "Epoch 51/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3757 - acc: 0.8402 - val_loss: 0.3739 - val_acc: 0.8524\n",
            "Epoch 52/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3680 - acc: 0.8408 - val_loss: 0.3732 - val_acc: 0.8543\n",
            "Epoch 53/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3687 - acc: 0.8427 - val_loss: 0.3723 - val_acc: 0.8552\n",
            "Epoch 54/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3728 - acc: 0.8418 - val_loss: 0.3718 - val_acc: 0.8519\n",
            "Epoch 55/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3649 - acc: 0.8461 - val_loss: 0.3709 - val_acc: 0.8529\n",
            "Epoch 56/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3713 - acc: 0.8390 - val_loss: 0.3706 - val_acc: 0.8533\n",
            "Epoch 57/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3654 - acc: 0.8412 - val_loss: 0.3702 - val_acc: 0.8510\n",
            "Epoch 58/130\n",
            "4900/4900 [==============================] - 0s 94us/step - loss: 0.3624 - acc: 0.8427 - val_loss: 0.3693 - val_acc: 0.8519\n",
            "Epoch 59/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3684 - acc: 0.8422 - val_loss: 0.3691 - val_acc: 0.8524\n",
            "Epoch 60/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3672 - acc: 0.8437 - val_loss: 0.3690 - val_acc: 0.8529\n",
            "Epoch 61/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3615 - acc: 0.8427 - val_loss: 0.3682 - val_acc: 0.8529\n",
            "Epoch 62/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3630 - acc: 0.8437 - val_loss: 0.3676 - val_acc: 0.8538\n",
            "Epoch 63/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3631 - acc: 0.8439 - val_loss: 0.3677 - val_acc: 0.8557\n",
            "Epoch 64/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3636 - acc: 0.8431 - val_loss: 0.3676 - val_acc: 0.8548\n",
            "Epoch 65/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3622 - acc: 0.8443 - val_loss: 0.3671 - val_acc: 0.8557\n",
            "Epoch 66/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3632 - acc: 0.8431 - val_loss: 0.3666 - val_acc: 0.8567\n",
            "Epoch 67/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3529 - acc: 0.8482 - val_loss: 0.3663 - val_acc: 0.8567\n",
            "Epoch 68/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3637 - acc: 0.8424 - val_loss: 0.3658 - val_acc: 0.8571\n",
            "Epoch 69/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3587 - acc: 0.8398 - val_loss: 0.3658 - val_acc: 0.8567\n",
            "Epoch 70/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3593 - acc: 0.8455 - val_loss: 0.3646 - val_acc: 0.8576\n",
            "Epoch 71/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3605 - acc: 0.8439 - val_loss: 0.3642 - val_acc: 0.8595\n",
            "Epoch 72/130\n",
            "4900/4900 [==============================] - 0s 94us/step - loss: 0.3567 - acc: 0.8439 - val_loss: 0.3638 - val_acc: 0.8590\n",
            "Epoch 73/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3607 - acc: 0.8441 - val_loss: 0.3638 - val_acc: 0.8595\n",
            "Epoch 74/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3599 - acc: 0.8439 - val_loss: 0.3634 - val_acc: 0.8595\n",
            "Epoch 75/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3548 - acc: 0.8463 - val_loss: 0.3635 - val_acc: 0.8586\n",
            "Epoch 76/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3594 - acc: 0.8435 - val_loss: 0.3629 - val_acc: 0.8590\n",
            "Epoch 77/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3588 - acc: 0.8455 - val_loss: 0.3628 - val_acc: 0.8562\n",
            "Epoch 78/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3561 - acc: 0.8465 - val_loss: 0.3626 - val_acc: 0.8586\n",
            "Epoch 79/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3552 - acc: 0.8445 - val_loss: 0.3621 - val_acc: 0.8590\n",
            "Epoch 80/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3563 - acc: 0.8441 - val_loss: 0.3620 - val_acc: 0.8590\n",
            "Epoch 81/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3572 - acc: 0.8473 - val_loss: 0.3615 - val_acc: 0.8600\n",
            "Epoch 82/130\n",
            "4900/4900 [==============================] - 0s 95us/step - loss: 0.3534 - acc: 0.8473 - val_loss: 0.3617 - val_acc: 0.8595\n",
            "Epoch 83/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3566 - acc: 0.8455 - val_loss: 0.3614 - val_acc: 0.8586\n",
            "Epoch 84/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3505 - acc: 0.8467 - val_loss: 0.3615 - val_acc: 0.8600\n",
            "Epoch 85/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3556 - acc: 0.8441 - val_loss: 0.3611 - val_acc: 0.8605\n",
            "Epoch 86/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3524 - acc: 0.8488 - val_loss: 0.3605 - val_acc: 0.8605\n",
            "Epoch 87/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3506 - acc: 0.8463 - val_loss: 0.3612 - val_acc: 0.8600\n",
            "Epoch 88/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3573 - acc: 0.8453 - val_loss: 0.3611 - val_acc: 0.8595\n",
            "Epoch 89/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3540 - acc: 0.8469 - val_loss: 0.3611 - val_acc: 0.8586\n",
            "Epoch 90/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3490 - acc: 0.8486 - val_loss: 0.3611 - val_acc: 0.8600\n",
            "Epoch 91/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3505 - acc: 0.8465 - val_loss: 0.3615 - val_acc: 0.8590\n",
            "Epoch 92/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3553 - acc: 0.8469 - val_loss: 0.3610 - val_acc: 0.8581\n",
            "Epoch 93/130\n",
            "4900/4900 [==============================] - 0s 93us/step - loss: 0.3532 - acc: 0.8457 - val_loss: 0.3607 - val_acc: 0.8586\n",
            "Epoch 94/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3511 - acc: 0.8443 - val_loss: 0.3608 - val_acc: 0.8590\n",
            "Epoch 95/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3509 - acc: 0.8488 - val_loss: 0.3599 - val_acc: 0.8576\n",
            "Epoch 96/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3507 - acc: 0.8449 - val_loss: 0.3592 - val_acc: 0.8586\n",
            "Epoch 97/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3498 - acc: 0.8476 - val_loss: 0.3598 - val_acc: 0.8590\n",
            "Epoch 98/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3540 - acc: 0.8439 - val_loss: 0.3606 - val_acc: 0.8600\n",
            "Epoch 99/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3491 - acc: 0.8473 - val_loss: 0.3607 - val_acc: 0.8595\n",
            "Epoch 100/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3535 - acc: 0.8433 - val_loss: 0.3607 - val_acc: 0.8610\n",
            "Epoch 101/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3513 - acc: 0.8473 - val_loss: 0.3592 - val_acc: 0.8595\n",
            "Epoch 102/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3531 - acc: 0.8490 - val_loss: 0.3593 - val_acc: 0.8600\n",
            "Epoch 103/130\n",
            "4900/4900 [==============================] - 0s 92us/step - loss: 0.3495 - acc: 0.8543 - val_loss: 0.3592 - val_acc: 0.8595\n",
            "Epoch 104/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3524 - acc: 0.8545 - val_loss: 0.3589 - val_acc: 0.8576\n",
            "Epoch 105/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3520 - acc: 0.8555 - val_loss: 0.3584 - val_acc: 0.8581\n",
            "Epoch 106/130\n",
            "4900/4900 [==============================] - 0s 93us/step - loss: 0.3496 - acc: 0.8565 - val_loss: 0.3584 - val_acc: 0.8595\n",
            "Epoch 107/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3481 - acc: 0.8567 - val_loss: 0.3582 - val_acc: 0.8586\n",
            "Epoch 108/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3517 - acc: 0.8557 - val_loss: 0.3591 - val_acc: 0.8595\n",
            "Epoch 109/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3533 - acc: 0.8539 - val_loss: 0.3585 - val_acc: 0.8595\n",
            "Epoch 110/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3530 - acc: 0.8524 - val_loss: 0.3585 - val_acc: 0.8595\n",
            "Epoch 111/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3496 - acc: 0.8547 - val_loss: 0.3578 - val_acc: 0.8590\n",
            "Epoch 112/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3529 - acc: 0.8559 - val_loss: 0.3583 - val_acc: 0.8590\n",
            "Epoch 113/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3484 - acc: 0.8586 - val_loss: 0.3576 - val_acc: 0.8586\n",
            "Epoch 114/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3476 - acc: 0.8600 - val_loss: 0.3580 - val_acc: 0.8595\n",
            "Epoch 115/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3488 - acc: 0.8555 - val_loss: 0.3575 - val_acc: 0.8610\n",
            "Epoch 116/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3504 - acc: 0.8535 - val_loss: 0.3577 - val_acc: 0.8648\n",
            "Epoch 117/130\n",
            "4900/4900 [==============================] - 0s 86us/step - loss: 0.3473 - acc: 0.8578 - val_loss: 0.3583 - val_acc: 0.8633\n",
            "Epoch 118/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3499 - acc: 0.8524 - val_loss: 0.3587 - val_acc: 0.8629\n",
            "Epoch 119/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3494 - acc: 0.8539 - val_loss: 0.3587 - val_acc: 0.8638\n",
            "Epoch 120/130\n",
            "4900/4900 [==============================] - 0s 90us/step - loss: 0.3480 - acc: 0.8535 - val_loss: 0.3586 - val_acc: 0.8624\n",
            "Epoch 121/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3492 - acc: 0.8563 - val_loss: 0.3588 - val_acc: 0.8624\n",
            "Epoch 122/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3466 - acc: 0.8563 - val_loss: 0.3591 - val_acc: 0.8633\n",
            "Epoch 123/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3471 - acc: 0.8547 - val_loss: 0.3597 - val_acc: 0.8610\n",
            "Epoch 124/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3481 - acc: 0.8571 - val_loss: 0.3585 - val_acc: 0.8629\n",
            "Epoch 125/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3462 - acc: 0.8553 - val_loss: 0.3584 - val_acc: 0.8643\n",
            "Epoch 126/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3442 - acc: 0.8563 - val_loss: 0.3590 - val_acc: 0.8614\n",
            "Epoch 127/130\n",
            "4900/4900 [==============================] - 0s 89us/step - loss: 0.3506 - acc: 0.8543 - val_loss: 0.3588 - val_acc: 0.8629\n",
            "Epoch 128/130\n",
            "4900/4900 [==============================] - 0s 88us/step - loss: 0.3440 - acc: 0.8618 - val_loss: 0.3577 - val_acc: 0.8614\n",
            "Epoch 129/130\n",
            "4900/4900 [==============================] - 0s 91us/step - loss: 0.3461 - acc: 0.8576 - val_loss: 0.3584 - val_acc: 0.8619\n",
            "Epoch 130/130\n",
            "4900/4900 [==============================] - 0s 87us/step - loss: 0.3461 - acc: 0.8563 - val_loss: 0.3568 - val_acc: 0.8610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwhRPXgVvEAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3a2dcd0-9911-4428-ee0f-29730c4aa01d"
      },
      "source": [
        "#model history\n",
        "print(model_history.history.keys())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUOHhjgew1z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "089169bb-ea06-484a-9b79-d18bffa0cdfe"
      },
      "source": [
        "#model performance\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxpgaWUAYY4ypkQWEMcaYGv0/5L8W86d1O7UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X8oxehK0fuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction and evaluating model\n",
        "y_pred=classifier.predict(X_test)\n",
        "y_pred = (y_pred>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbp7VjMk1Arm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a0c8907b-28c2-47c3-9792-a17976a46d99"
      },
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test,y_pred)\n",
        "cm"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2299,   88],\n",
              "       [ 326,  287]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMHrx2Ju1aOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1c4984d-fda6-446a-9e92-d3b89e916f10"
      },
      "source": [
        "#calculating model accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "score = accuracy_score(y_pred,Y_test)\n",
        "score"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.862"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGILycav1sX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}